{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz4Js06sdzoX"
   },
   "source": [
    "### Boolean Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sFO9NHwdISCZ"
   },
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "docs = {\n",
    "    \"doc1\": \"artificial intelligence and machine learning revolutionize modern technology\",\n",
    "    \"doc2\": \"natural language processing enables computers to understand human language\",\n",
    "    \"doc3\": \"computer vision algorithms analyze and interpret visual data\"\n",
    "}\n",
    "\n",
    "# Preprocessing: lowercase + split\n",
    "def preprocess(text):\n",
    "    return text.lower().split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-XOcfPlzn_8N"
   },
   "outputs": [],
   "source": [
    "# Build term-document matrix (binary)\n",
    "terms = {}\n",
    "doc_list = list(docs.keys())\n",
    "\n",
    "for i, (doc, text) in enumerate(docs.items()):\n",
    "    words = set(preprocess(text))\n",
    "    for word in words:\n",
    "        if word not in terms:\n",
    "            terms[word] = [0] * len(docs)\n",
    "        terms[word][i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaRhckk9ds0a",
    "outputId": "1e5043c6-398a-4737-b3cf-55938a115bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Term-Document Matrix:\n",
      "machine        : [1, 0, 0]\n",
      "revolutionize  : [1, 0, 0]\n",
      "artificial     : [1, 0, 0]\n",
      "learning       : [1, 0, 0]\n",
      "technology     : [1, 0, 0]\n",
      "intelligence   : [1, 0, 0]\n",
      "modern         : [1, 0, 0]\n",
      "and            : [1, 0, 1]\n",
      "to             : [0, 1, 0]\n",
      "language       : [0, 1, 0]\n",
      "natural        : [0, 1, 0]\n",
      "processing     : [0, 1, 0]\n",
      "understand     : [0, 1, 0]\n",
      "enables        : [0, 1, 0]\n",
      "human          : [0, 1, 0]\n",
      "computers      : [0, 1, 0]\n",
      "data           : [0, 0, 1]\n",
      "computer       : [0, 0, 1]\n",
      "visual         : [0, 0, 1]\n",
      "vision         : [0, 0, 1]\n",
      "interpret      : [0, 0, 1]\n",
      "analyze        : [0, 0, 1]\n",
      "algorithms     : [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Show matrix\n",
    "print(\"\\nTerm-Document Matrix:\")\n",
    "for term, vec in terms.items():\n",
    "    print(f\"{term:15}: {vec}\")\n",
    "\n",
    "# Evaluate boolean query (supports AND, OR, NOT)\n",
    "def evaluate(query):\n",
    "    query = query.lower().split()\n",
    "    result = None\n",
    "    operator = None\n",
    "    i = 0\n",
    "\n",
    "    while i < len(query):\n",
    "        if query[i] == 'not':\n",
    "            word = query[i + 1]\n",
    "            vec = terms.get(word, [0] * len(docs))\n",
    "            vec = [1 - x for x in vec]\n",
    "            i += 2\n",
    "        elif query[i] in ['and', 'or']:\n",
    "            operator = query[i]\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            word = query[i]\n",
    "            vec = terms.get(word, [0] * len(docs))\n",
    "            i += 1\n",
    "\n",
    "        if result is None:\n",
    "            result = vec\n",
    "        else:\n",
    "            if operator == 'and':\n",
    "                result = [a & b for a, b in zip(result, vec)]\n",
    "            elif operator == 'or':\n",
    "                result = [a | b for a, b in zip(result, vec)]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiaYQqejdvsX",
    "outputId": "6a54d20c-2ea4-48be-b547-3016f02dc1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Boolean query (AND, OR, NOT):  machine OR learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching Documents: ['doc1']\n"
     ]
    }
   ],
   "source": [
    "# Get user query\n",
    "query = input(\"\\nEnter Boolean query (AND, OR, NOT): \")\n",
    "# Example queries to try:\n",
    "# - artificial AND intelligence\n",
    "# - machine OR learning\n",
    "# - NOT language\n",
    "\n",
    "# Evaluate\n",
    "result_vec = evaluate(query)\n",
    "matches = [doc_list[i] for i, v in enumerate(result_vec) if v == 1]\n",
    "\n",
    "# Show result\n",
    "print(\"\\nMatching Documents:\", matches if matches else \"No match found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DEtDOiXhzmc"
   },
   "source": [
    "### Term Weighthing Meachanism - TF, IDF, TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Se8z7Ponh6RT",
    "outputId": "8ff618db-ac4f-47ab-e4a7-8086bd61d956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed docs: {'doc1': ['deep', 'learning', 'neural', 'networks', 'transform', 'artificial', 'intelligence'], 'doc2': ['software', 'engineering', 'principles', 'guide', 'system', 'development'], 'doc3': ['data', 'science', 'analytics', 'reveal', 'meaningful', 'business', 'insights']}\n",
      "Vocabulary: ['analytics', 'artificial', 'business', 'data', 'deep', 'development', 'engineering', 'guide', 'insights', 'intelligence', 'learning', 'meaningful', 'networks', 'neural', 'principles', 'reveal', 'science', 'software', 'system', 'transform']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Sample documents\n",
    "documents = {\n",
    "    \"doc1\": \"deep learning neural networks transform artificial intelligence\",\n",
    "    \"doc2\": \"software engineering principles guide system development\",\n",
    "    \"doc3\": \"data science analytics reveal meaningful business insights\"\n",
    "}\n",
    "\n",
    "def preprocess(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = set()\n",
    "preprocessed_docs = {}\n",
    "\n",
    "for name, text in documents.items():\n",
    "    tokens = preprocess(text)\n",
    "    preprocessed_docs[name] = tokens\n",
    "    vocab.update(tokens)\n",
    "\n",
    "print(f'Preprocessed docs: {preprocessed_docs}')\n",
    "vocab = sorted(list(vocab))\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmRITbkbiWDx"
   },
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dPEgHfV7iSFZ"
   },
   "outputs": [],
   "source": [
    "def compute_tf(doc_tokens, vocab):\n",
    "    tf = {}\n",
    "    total_terms = len(doc_tokens)\n",
    "    for term in vocab:\n",
    "        tf[term] = doc_tokens.count(term) / total_terms\n",
    "    return tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFXQ2M_-iav5"
   },
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ihL65qoEiYTR"
   },
   "outputs": [],
   "source": [
    "def compute_idf(all_docs, vocab):\n",
    "    N = len(all_docs)\n",
    "    idf = {}\n",
    "    for term in vocab:\n",
    "        df = sum(1 for doc in all_docs.values() if term in doc)\n",
    "        idf[term] = math.log(N / (df + 1)) + 1  # +1 smoothing\n",
    "    return idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsL1q6bnif5x"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kCvMXakOidl2"
   },
   "outputs": [],
   "source": [
    "def compute_tfidf(tf, idf):\n",
    "    tfidf = {}\n",
    "    for term in tf:\n",
    "        tfidf[term] = tf[term] * idf[term]\n",
    "    return tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SzEru12iii8",
    "outputId": "69a230a0-af54-4251-a574-8a3bc71123b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document: doc1\n",
      "TF:      {'analytics': 0.0, 'artificial': 0.143, 'business': 0.0, 'data': 0.0, 'deep': 0.143, 'development': 0.0, 'engineering': 0.0, 'guide': 0.0, 'insights': 0.0, 'intelligence': 0.143, 'learning': 0.143, 'meaningful': 0.0, 'networks': 0.143, 'neural': 0.143, 'principles': 0.0, 'reveal': 0.0, 'science': 0.0, 'software': 0.0, 'system': 0.0, 'transform': 0.143}\n",
      "TF-IDF:  {'analytics': 0.0, 'artificial': 0.201, 'business': 0.0, 'data': 0.0, 'deep': 0.201, 'development': 0.0, 'engineering': 0.0, 'guide': 0.0, 'insights': 0.0, 'intelligence': 0.201, 'learning': 0.201, 'meaningful': 0.0, 'networks': 0.201, 'neural': 0.201, 'principles': 0.0, 'reveal': 0.0, 'science': 0.0, 'software': 0.0, 'system': 0.0, 'transform': 0.201}\n",
      "\n",
      "Document: doc2\n",
      "TF:      {'analytics': 0.0, 'artificial': 0.0, 'business': 0.0, 'data': 0.0, 'deep': 0.0, 'development': 0.167, 'engineering': 0.167, 'guide': 0.167, 'insights': 0.0, 'intelligence': 0.0, 'learning': 0.0, 'meaningful': 0.0, 'networks': 0.0, 'neural': 0.0, 'principles': 0.167, 'reveal': 0.0, 'science': 0.0, 'software': 0.167, 'system': 0.167, 'transform': 0.0}\n",
      "TF-IDF:  {'analytics': 0.0, 'artificial': 0.0, 'business': 0.0, 'data': 0.0, 'deep': 0.0, 'development': 0.234, 'engineering': 0.234, 'guide': 0.234, 'insights': 0.0, 'intelligence': 0.0, 'learning': 0.0, 'meaningful': 0.0, 'networks': 0.0, 'neural': 0.0, 'principles': 0.234, 'reveal': 0.0, 'science': 0.0, 'software': 0.234, 'system': 0.234, 'transform': 0.0}\n",
      "\n",
      "Document: doc3\n",
      "TF:      {'analytics': 0.143, 'artificial': 0.0, 'business': 0.143, 'data': 0.143, 'deep': 0.0, 'development': 0.0, 'engineering': 0.0, 'guide': 0.0, 'insights': 0.143, 'intelligence': 0.0, 'learning': 0.0, 'meaningful': 0.143, 'networks': 0.0, 'neural': 0.0, 'principles': 0.0, 'reveal': 0.143, 'science': 0.143, 'software': 0.0, 'system': 0.0, 'transform': 0.0}\n",
      "TF-IDF:  {'analytics': 0.201, 'artificial': 0.0, 'business': 0.201, 'data': 0.201, 'deep': 0.0, 'development': 0.0, 'engineering': 0.0, 'guide': 0.0, 'insights': 0.201, 'intelligence': 0.0, 'learning': 0.0, 'meaningful': 0.201, 'networks': 0.0, 'neural': 0.0, 'principles': 0.0, 'reveal': 0.201, 'science': 0.201, 'software': 0.0, 'system': 0.0, 'transform': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Compute IDF once for all docs\n",
    "idf = compute_idf(preprocessed_docs, vocab)\n",
    "\n",
    "# For each document, compute TF and TF-IDF\n",
    "for name, tokens in preprocessed_docs.items():\n",
    "    tf = compute_tf(tokens, vocab)\n",
    "    tfidf = compute_tfidf(tf, idf)\n",
    "\n",
    "    print(f\"\\nDocument: {name}\")\n",
    "    print(\"TF:     \", {k: round(v, 3) for k, v in tf.items()})\n",
    "    print(\"TF-IDF: \", {k: round(v, 3) for k, v in tfidf.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FolU7IkXkDhc"
   },
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APxgwi39kFr3",
    "outputId": "d023a918-92d7-4a27-d6c3-c8173046e48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['applications', 'architecture', 'development', 'enterprise', 'java', 'language', 'learning', 'machine', 'programming', 'python', 'require', 'robust', 'software', 'supports']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"python programming language supports machine learning development\",\n",
    "    \"java enterprise applications require robust software architecture\",\n",
    "]\n",
    "\n",
    "# Build vocabulary (unique words in all documents)\n",
    "def build_vocab(docs):\n",
    "    vocab_set = set()\n",
    "    for doc in docs:\n",
    "        vocab_set.update(doc.split())\n",
    "    return sorted(vocab_set)\n",
    "\n",
    "vocab = build_vocab(documents)\n",
    "print(\"Vocabulary:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Sb9QvvHOkJW7"
   },
   "outputs": [],
   "source": [
    "# Create Bag of Words vector for a document\n",
    "def bow_vector(doc, vocab):\n",
    "    words = doc.split()\n",
    "    return [words.count(term) for term in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dghu56vRkNx0",
    "outputId": "cd2fc825-6db1-48c9-b955-653ad5a3f48e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BoW Vector for Document 1: [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "BoW Vector for Document 2: [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "Cosine Similarity between Doc1 and Doc2: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between two vectors\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "    magnitude1 = math.sqrt(sum(a * a for a in vec1))\n",
    "    magnitude2 = math.sqrt(sum(b * b for b in vec2))\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "# Create BoW vectors for all documents\n",
    "vectors = [bow_vector(doc, vocab) for doc in documents]\n",
    "\n",
    "# Compute similarity between first and second documents\n",
    "similarity = cosine_similarity(vectors[0], vectors[1])\n",
    "\n",
    "print(\"\\nBoW Vector for Document 1:\", vectors[0])\n",
    "print(\"BoW Vector for Document 2:\", vectors[1])\n",
    "print(\"Cosine Similarity between Doc1 and Doc2:\", round(similarity, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S12orfSJBnns"
   },
   "source": [
    "**Kullback–Leibler (KL) divergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['algorithms', 'analysis', 'and', 'applications', 'are', 'artificial', 'computer', 'data', 'database', 'deep', 'for', 'image', 'in', 'intelligence', 'language', 'learning', 'machine', 'management', 'mining', 'models', 'natural', 'networks', 'neural', 'pattern', 'processing', 'recognition', 'solutions', 'storage', 'systems', 'techniques', 'text', 'used', 'vision']\n",
      "Query tokens: ['machine', 'learning', 'algorithms', 'neural', 'networks']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Sample query and documents\n",
    "query = \"machine learning algorithms neural networks\"\n",
    "documents = {\n",
    "    \"doc1\": \"machine learning algorithms are used in artificial intelligence applications\",\n",
    "    \"doc2\": \"neural networks deep learning models for pattern recognition\",\n",
    "    \"doc3\": \"database management systems and data storage solutions\",\n",
    "    \"doc4\": \"natural language processing and text mining techniques\",\n",
    "    \"doc5\": \"computer vision algorithms for image recognition and analysis\"\n",
    "}\n",
    "\n",
    "def preprocess(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Build vocabulary from query and documents\n",
    "vocab = set()\n",
    "query_tokens = preprocess(query)\n",
    "vocab.update(query_tokens)\n",
    "\n",
    "doc_tokens = {}\n",
    "for doc_id, text in documents.items():\n",
    "    tokens = preprocess(text)\n",
    "    doc_tokens[doc_id] = tokens\n",
    "    vocab.update(tokens)\n",
    "\n",
    "vocab = sorted(list(vocab))\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Query tokens:\", query_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Model P(w|Q):\n",
      "algorithms  : 0.1325\n",
      "analysis    : 0.0120\n",
      "and         : 0.0120\n",
      "applications: 0.0120\n",
      "are         : 0.0120\n",
      "artificial  : 0.0120\n",
      "computer    : 0.0120\n",
      "data        : 0.0120\n",
      "database    : 0.0120\n",
      "deep        : 0.0120\n",
      "for         : 0.0120\n",
      "image       : 0.0120\n",
      "in          : 0.0120\n",
      "intelligence: 0.0120\n",
      "language    : 0.0120\n",
      "learning    : 0.1325\n",
      "machine     : 0.1325\n",
      "management  : 0.0120\n",
      "mining      : 0.0120\n",
      "models      : 0.0120\n",
      "natural     : 0.0120\n",
      "networks    : 0.1325\n",
      "neural      : 0.1325\n",
      "pattern     : 0.0120\n",
      "processing  : 0.0120\n",
      "recognition : 0.0120\n",
      "solutions   : 0.0120\n",
      "storage     : 0.0120\n",
      "systems     : 0.0120\n",
      "techniques  : 0.0120\n",
      "text        : 0.0120\n",
      "used        : 0.0120\n",
      "vision      : 0.0120\n"
     ]
    }
   ],
   "source": [
    "# Calculate probability distribution for query model\n",
    "def query_model(query_tokens, vocab, smoothing=0.1):\n",
    "    \"\"\"Create probability distribution for query using maximum likelihood with smoothing\"\"\"\n",
    "    prob_dist = {}\n",
    "    query_length = len(query_tokens)\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    for term in vocab:\n",
    "        term_count = query_tokens.count(term)\n",
    "        # Laplace smoothing\n",
    "        prob_dist[term] = (term_count + smoothing) / (query_length + smoothing * vocab_size)\n",
    "    \n",
    "    return prob_dist\n",
    "\n",
    "# Calculate probability distribution for document model  \n",
    "def document_model(doc_tokens, vocab, smoothing=0.1):\n",
    "    \"\"\"Create probability distribution for document using maximum likelihood with smoothing\"\"\"\n",
    "    prob_dist = {}\n",
    "    doc_length = len(doc_tokens)\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    for term in vocab:\n",
    "        term_count = doc_tokens.count(term)\n",
    "        # Laplace smoothing\n",
    "        prob_dist[term] = (term_count + smoothing) / (doc_length + smoothing * vocab_size)\n",
    "    \n",
    "    return prob_dist\n",
    "\n",
    "# Calculate query model\n",
    "P_Q = query_model(query_tokens, vocab)\n",
    "print(\"\\nQuery Model P(w|Q):\")\n",
    "for term, prob in P_Q.items():\n",
    "    print(f\"{term:12}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Models and KL Divergences:\n",
      "==================================================\n",
      "\n",
      "DOC1 Model P(w|D):\n",
      "algorithms  : 0.0894\n",
      "applications: 0.0894\n",
      "are         : 0.0894\n",
      "artificial  : 0.0894\n",
      "in          : 0.0894\n",
      "intelligence: 0.0894\n",
      "learning    : 0.0894\n",
      "machine     : 0.0894\n",
      "used        : 0.0894\n",
      "KL Divergence D_KL(Q || doc1): 0.8556\n",
      "\n",
      "DOC2 Model P(w|D):\n",
      "deep        : 0.0973\n",
      "for         : 0.0973\n",
      "learning    : 0.0973\n",
      "models      : 0.0973\n",
      "networks    : 0.0973\n",
      "neural      : 0.0973\n",
      "pattern     : 0.0973\n",
      "recognition : 0.0973\n",
      "KL Divergence D_KL(Q || doc2): 0.7997\n",
      "\n",
      "DOC3 Model P(w|D):\n",
      "and         : 0.1068\n",
      "data        : 0.1068\n",
      "database    : 0.1068\n",
      "management  : 0.1068\n",
      "solutions   : 0.1068\n",
      "storage     : 0.1068\n",
      "systems     : 0.1068\n",
      "KL Divergence D_KL(Q || doc3): 1.6026\n",
      "\n",
      "DOC4 Model P(w|D):\n",
      "and         : 0.1068\n",
      "language    : 0.1068\n",
      "mining      : 0.1068\n",
      "natural     : 0.1068\n",
      "processing  : 0.1068\n",
      "techniques  : 0.1068\n",
      "text        : 0.1068\n",
      "KL Divergence D_KL(Q || doc4): 1.6026\n",
      "\n",
      "DOC5 Model P(w|D):\n",
      "algorithms  : 0.0973\n",
      "analysis    : 0.0973\n",
      "and         : 0.0973\n",
      "computer    : 0.0973\n",
      "for         : 0.0973\n",
      "image       : 0.0973\n",
      "recognition : 0.0973\n",
      "vision      : 0.0973\n",
      "KL Divergence D_KL(Q || doc5): 1.3775\n",
      "\n",
      "==================================================\n",
      "DOCUMENT RANKING (Lower KL divergence = Better match):\n",
      "==================================================\n",
      "Rank 1: doc2 (KL divergence: 0.7997)\n",
      "         Text: 'neural networks deep learning models for pattern recognition'\n",
      "\n",
      "Rank 2: doc1 (KL divergence: 0.8556)\n",
      "         Text: 'machine learning algorithms are used in artificial intelligence applications'\n",
      "\n",
      "Rank 3: doc5 (KL divergence: 1.3775)\n",
      "         Text: 'computer vision algorithms for image recognition and analysis'\n",
      "\n",
      "Rank 4: doc3 (KL divergence: 1.6026)\n",
      "         Text: 'database management systems and data storage solutions'\n",
      "\n",
      "Rank 5: doc4 (KL divergence: 1.6026)\n",
      "         Text: 'natural language processing and text mining techniques'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KL Divergence calculation\n",
    "def kl_divergence(P, Q):\n",
    "    \"\"\"Calculate KL divergence from P to Q: D_KL(P || Q)\"\"\"\n",
    "    kl_div = 0.0\n",
    "    for term in P:\n",
    "        if P[term] > 0:  # Only calculate for terms with non-zero probability in P\n",
    "            if Q[term] > 0:  # Avoid log(0)\n",
    "                kl_div += P[term] * math.log(P[term] / Q[term])\n",
    "            else:\n",
    "                # If Q[term] = 0 but P[term] > 0, KL divergence is infinite\n",
    "                # In practice, we use smoothing to avoid this\n",
    "                kl_div += float('inf')\n",
    "    return kl_div\n",
    "\n",
    "# Calculate document models and KL divergences\n",
    "print(\"\\nDocument Models and KL Divergences:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "scores = {}\n",
    "for doc_id, tokens in doc_tokens.items():\n",
    "    P_D = document_model(tokens, vocab)\n",
    "    \n",
    "    print(f\"\\n{doc_id.upper()} Model P(w|D):\")\n",
    "    for term, prob in P_D.items():\n",
    "        if prob > 0.01:  # Only show terms with reasonable probability\n",
    "            print(f\"{term:12}: {prob:.4f}\")\n",
    "    \n",
    "    # Calculate KL divergence from Query to Document: D_KL(P_Q || P_D)\n",
    "    kl_score = kl_divergence(P_Q, P_D)\n",
    "    scores[doc_id] = kl_score\n",
    "    \n",
    "    print(f\"KL Divergence D_KL(Q || {doc_id}): {kl_score:.4f}\")\n",
    "\n",
    "# Rank documents (lower KL divergence = better match)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"DOCUMENT RANKING (Lower KL divergence = Better match):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "ranked_docs = sorted(scores.items(), key=lambda x: x[1])\n",
    "for rank, (doc_id, score) in enumerate(ranked_docs, 1):\n",
    "    print(f\"Rank {rank}: {doc_id} (KL divergence: {score:.4f})\")\n",
    "    print(f\"         Text: '{documents[doc_id]}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alternative Direction: D_KL(Document || Query)\n",
      "==================================================\n",
      "D_KL(doc1 || Q): 0.8543\n",
      "D_KL(doc2 || Q): 0.8161\n",
      "D_KL(doc3 || Q): 1.4603\n",
      "D_KL(doc4 || Q): 1.4603\n",
      "D_KL(doc5 || Q): 1.2405\n",
      "\n",
      "============================================================\n",
      "COMPARISON OF BOTH DIRECTIONS:\n",
      "============================================================\n",
      "Document D_KL(Q||D)   D_KL(D||Q)   Text\n",
      "------------------------------------------------------------\n",
      "doc1     0.8556       0.8543       machine learning algorithms ar...\n",
      "doc2     0.7997       0.8161       neural networks deep learning ...\n",
      "doc3     1.6026       1.4603       database management systems an...\n",
      "doc4     1.6026       1.4603       natural language processing an...\n",
      "doc5     1.3775       1.2405       computer vision algorithms for...\n",
      "\n",
      "Note: In IR, we typically use D_KL(Q || D) where:\n",
      "- Lower divergence means the document model is closer to the query model\n",
      "- This measures how much 'information is lost' when using document model instead of query model\n"
     ]
    }
   ],
   "source": [
    "# Alternative: KL divergence from Document to Query D_KL(P_D || P_Q)\n",
    "print(\"\\nAlternative Direction: D_KL(Document || Query)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "alt_scores = {}\n",
    "for doc_id, tokens in doc_tokens.items():\n",
    "    P_D = document_model(tokens, vocab)\n",
    "    kl_score_alt = kl_divergence(P_D, P_Q)\n",
    "    alt_scores[doc_id] = kl_score_alt\n",
    "    print(f\"D_KL({doc_id} || Q): {kl_score_alt:.4f}\")\n",
    "\n",
    "# Compare both directions\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COMPARISON OF BOTH DIRECTIONS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Document':<8} {'D_KL(Q||D)':<12} {'D_KL(D||Q)':<12} {'Text'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for doc_id in documents.keys():\n",
    "    print(f\"{doc_id:<8} {scores[doc_id]:<12.4f} {alt_scores[doc_id]:<12.4f} {documents[doc_id][:30]}...\")\n",
    "\n",
    "print(f\"\\nNote: In IR, we typically use D_KL(Q || D) where:\")\n",
    "print(\"- Lower divergence means the document model is closer to the query model\")\n",
    "print(\"- This measures how much 'information is lost' when using document model instead of query model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
