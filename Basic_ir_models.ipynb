{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aba5205e-4ac6-4be2-90c9-188222cd2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4514092-96ca-4ce4-995d-d35c12e892f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a dream that one day every valley shall be exalted, every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight; 'and the glory of the Lord shall be revealed and all flesh shall see it together.'\n",
      "This is our hope. This is the faith that I go back to the South with. With this faith, we will be able to hew out of the mountain of despair a stone of hope. With this faith, we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"I have a dream that one day every valley shall be exalted, every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight; 'and the glory of the Lord shall be revealed and all flesh shall see it together.'\n",
    "\n",
    "This is our hope. This is the faith that I go back to the South with. With this faith, we will be able to hew out of the mountain of despair a stone of hope. With this faith, we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\"\"\"\n",
    "documents = [p.strip() for p in txt.split('\\n\\n') if p.strip()]\n",
    "\n",
    "for each_doc in documents:\n",
    "    print(each_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "693a94ac-6175-4ca3-a10f-30c5e47ddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1725d65-ef65-4da0-9b08-a9e798f234f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dream\n",
      "one\n",
      "day\n",
      "every\n",
      "valley\n",
      "shall\n",
      "exalted\n",
      "every\n",
      "hill\n",
      "mountain\n",
      "shall\n",
      "made\n",
      "low\n",
      "rough\n",
      "places\n",
      "made\n",
      "plain\n",
      "crooked\n",
      "places\n",
      "made\n",
      "straight\n",
      "glory\n",
      "lord\n",
      "shall\n",
      "revealed\n",
      "flesh\n",
      "shall\n",
      "see\n",
      "together\n",
      "hope\n",
      "faith\n",
      "back\n",
      "south\n",
      "faith\n",
      "able\n",
      "hew\n",
      "mountain\n",
      "despair\n",
      "stone\n",
      "hope\n",
      "faith\n",
      "able\n",
      "transform\n",
      "jangling\n",
      "discords\n",
      "nation\n",
      "beautiful\n",
      "symphony\n",
      "brotherhood\n"
     ]
    }
   ],
   "source": [
    "def tokenize(txt):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', txt.lower())\n",
    "    return [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "\n",
    "tokenized_docs = [tokenize(doc) for doc in documents]\n",
    "\n",
    "for each_tokenize_doc in tokenized_doc:\n",
    "    print(each_tokenize_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119a8b5-99d8-4c14-b7cc-5a15367da2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
