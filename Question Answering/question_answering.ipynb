{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29919b5",
   "metadata": {},
   "source": [
    "# Question Answering System\n",
    "## Similarity-based Model Training + Conditional Answering + Simple RAG System\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Similarity-based Question Answering**: Finding the most relevant documents using TF-IDF and cosine similarity\n",
    "2. **Conditional Answering**: Providing answers based on similarity thresholds\n",
    "3. **Simple RAG System**: Retrieval-Augmented Generation for better question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30820572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13022e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base: Documents for Question Answering\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.\",\n",
    "    \"Python is a popular programming language used for data science, web development, and artificial intelligence.\",\n",
    "    \"Natural language processing involves teaching computers to understand and process human language.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to solve complex problems like image recognition.\",\n",
    "    \"Data science combines statistics, programming, and domain expertise to extract insights from data.\",\n",
    "    \"Computer vision enables machines to interpret and understand visual information from the world.\",\n",
    "    \"Supervised learning uses labeled data to train models that can make predictions on new data.\",\n",
    "    \"Unsupervised learning finds hidden patterns in data without using labeled examples.\",\n",
    "    \"Reinforcement learning trains agents to make decisions by learning from rewards and penalties.\",\n",
    "    \"Big data refers to large, complex datasets that require special tools and techniques to process.\"\n",
    "]\n",
    "\n",
    "# Sample Question-Answer pairs for training\n",
    "qa_pairs = [\n",
    "    {\"question\": \"What is machine learning?\", \"answer\": \"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.\"},\n",
    "    {\"question\": \"Which programming language is popular for AI?\", \"answer\": \"Python is a popular programming language used for data science, web development, and artificial intelligence.\"},\n",
    "    {\"question\": \"What does NLP stand for?\", \"answer\": \"Natural language processing involves teaching computers to understand and process human language.\"},\n",
    "    {\"question\": \"How does deep learning work?\", \"answer\": \"Deep learning uses neural networks with multiple layers to solve complex problems like image recognition.\"},\n",
    "    {\"question\": \"What is supervised learning?\", \"answer\": \"Supervised learning uses labeled data to train models that can make predictions on new data.\"}\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base created with {len(documents)} documents\")\n",
    "print(f\"Training data contains {len(qa_pairs)} Q&A pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing Functions\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text for better similarity matching\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extract important keywords from text\"\"\"\n",
    "    # Simple keyword extraction (remove common stop words)\n",
    "    stop_words = {'is', 'are', 'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "    words = preprocess_text(text).split()\n",
    "    keywords = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "    return keywords\n",
    "\n",
    "# Test preprocessing\n",
    "sample_question = \"What is machine learning?\"\n",
    "print(f\"Original: {sample_question}\")\n",
    "print(f\"Preprocessed: {preprocess_text(sample_question)}\")\n",
    "print(f\"Keywords: {extract_keywords(sample_question)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeba502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity-based Question Answering Model\n",
    "class SimilarityQA:\n",
    "    def __init__(self, threshold=0.3):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.documents = []\n",
    "        self.qa_pairs = []\n",
    "        self.doc_vectors = None\n",
    "        self.qa_vectors = None\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def train(self, documents, qa_pairs):\n",
    "        \"\"\"Train the model with documents and Q&A pairs\"\"\"\n",
    "        self.documents = documents\n",
    "        self.qa_pairs = qa_pairs\n",
    "        \n",
    "        # Create vectors for documents\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(documents)\n",
    "        \n",
    "        # Create vectors for questions in Q&A pairs\n",
    "        questions = [pair['question'] for pair in qa_pairs]\n",
    "        self.qa_vectors = self.vectorizer.transform(questions)\n",
    "        \n",
    "        print(f\"Model trained with {len(documents)} documents and {len(qa_pairs)} Q&A pairs\")\n",
    "    \n",
    "    def find_best_answer(self, question):\n",
    "        \"\"\"Find the best answer using similarity matching\"\"\"\n",
    "        # Vectorize the input question\n",
    "        question_vector = self.vectorizer.transform([question])\n",
    "        \n",
    "        # Calculate similarity with Q&A pairs (exact match)\n",
    "        qa_similarities = cosine_similarity(question_vector, self.qa_vectors)[0]\n",
    "        best_qa_idx = np.argmax(qa_similarities)\n",
    "        best_qa_score = qa_similarities[best_qa_idx]\n",
    "        \n",
    "        # Calculate similarity with documents (retrieval)\n",
    "        doc_similarities = cosine_similarity(question_vector, self.doc_vectors)[0]\n",
    "        best_doc_idx = np.argmax(doc_similarities)\n",
    "        best_doc_score = doc_similarities[best_doc_idx]\n",
    "        \n",
    "        # Conditional answering based on threshold\n",
    "        if best_qa_score > self.threshold:\n",
    "            return {\n",
    "                'answer': self.qa_pairs[best_qa_idx]['answer'],\n",
    "                'confidence': best_qa_score,\n",
    "                'source': 'QA_pairs',\n",
    "                'method': 'exact_match'\n",
    "            }\n",
    "        elif best_doc_score > self.threshold:\n",
    "            return {\n",
    "                'answer': self.documents[best_doc_idx],\n",
    "                'confidence': best_doc_score,\n",
    "                'source': 'documents',\n",
    "                'method': 'similarity_retrieval'\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'answer': \"Sorry, I couldn't find a relevant answer to your question.\",\n",
    "                'confidence': max(best_qa_score, best_doc_score),\n",
    "                'source': 'none',\n",
    "                'method': 'below_threshold'\n",
    "            }\n",
    "\n",
    "# Initialize and train the model\n",
    "qa_model = SimilarityQA(threshold=0.2)\n",
    "qa_model.train(documents, qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad89760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Similarity-based Question Answering\n",
    "test_questions = [\n",
    "    \"What is machine learning?\",  # Exact match in Q&A pairs\n",
    "    \"Tell me about deep learning\",  # Should find from documents\n",
    "    \"What is Python used for?\",  # Similar to Q&A pair\n",
    "    \"How does computer vision work?\",  # Should find from documents\n",
    "    \"What is quantum computing?\"  # No relevant answer\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMILARITY-BASED QUESTION ANSWERING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    result = qa_model.find_best_answer(question)\n",
    "    print(f\"   Answer: {result['answer']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"   Source: {result['source']}\")\n",
    "    print(f\"   Method: {result['method']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG (Retrieval-Augmented Generation) System\n",
    "class SimpleRAG:\n",
    "    def __init__(self, top_k=3):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.documents = []\n",
    "        self.doc_vectors = None\n",
    "        self.top_k = top_k\n",
    "        \n",
    "    def add_documents(self, documents):\n",
    "        \"\"\"Add documents to the knowledge base\"\"\"\n",
    "        self.documents = documents\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(documents)\n",
    "        print(f\"RAG system loaded with {len(documents)} documents\")\n",
    "    \n",
    "    def retrieve_documents(self, query):\n",
    "        \"\"\"Retrieve top-k most relevant documents\"\"\"\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vector, self.doc_vectors)[0]\n",
    "        \n",
    "        # Get top-k most similar documents\n",
    "        top_indices = np.argsort(similarities)[::-1][:self.top_k]\n",
    "        retrieved_docs = []\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            if similarities[idx] > 0:  # Only include relevant documents\n",
    "                retrieved_docs.append({\n",
    "                    'document': self.documents[idx],\n",
    "                    'similarity': similarities[idx],\n",
    "                    'index': idx\n",
    "                })\n",
    "        \n",
    "        return retrieved_docs\n",
    "    \n",
    "    def generate_answer(self, query, retrieved_docs):\n",
    "        \"\"\"Generate answer based on retrieved documents\"\"\"\n",
    "        if not retrieved_docs:\n",
    "            return \"No relevant documents found for your query.\"\n",
    "        \n",
    "        # Simple answer generation using the most relevant document\n",
    "        best_doc = retrieved_docs[0]\n",
    "        \n",
    "        # Extract relevant sentences (simple approach)\n",
    "        sentences = best_doc['document'].split('.')\n",
    "        query_keywords = extract_keywords(query)\n",
    "        \n",
    "        # Find sentence with most keyword matches\n",
    "        best_sentence = \"\"\n",
    "        max_matches = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                sentence_keywords = extract_keywords(sentence)\n",
    "                matches = len(set(query_keywords) & set(sentence_keywords))\n",
    "                if matches > max_matches:\n",
    "                    max_matches = matches\n",
    "                    best_sentence = sentence.strip()\n",
    "        \n",
    "        if best_sentence:\n",
    "            return best_sentence + \".\"\n",
    "        else:\n",
    "            return best_doc['document']\n",
    "    \n",
    "    def answer_question(self, query):\n",
    "        \"\"\"Complete RAG pipeline: retrieve + generate\"\"\"\n",
    "        # Step 1: Retrieve relevant documents\n",
    "        retrieved_docs = self.retrieve_documents(query)\n",
    "        \n",
    "        # Step 2: Generate answer\n",
    "        answer = self.generate_answer(query, retrieved_docs)\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'answer': answer,\n",
    "            'retrieved_documents': len(retrieved_docs),\n",
    "            'top_similarity': retrieved_docs[0]['similarity'] if retrieved_docs else 0\n",
    "        }\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = SimpleRAG(top_k=3)\n",
    "rag_system.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG System\n",
    "rag_test_questions = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"How does machine learning work?\",\n",
    "    \"Tell me about neural networks\",\n",
    "    \"What is the difference between supervised and unsupervised learning?\",\n",
    "    \"How is Python used in data science?\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAG SYSTEM QUESTION ANSWERING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(rag_test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    result = rag_system.answer_question(question)\n",
    "    print(f\"   Answer: {result['answer']}\")\n",
    "    print(f\"   Retrieved docs: {result['retrieved_documents']}\")\n",
    "    print(f\"   Top similarity: {result['top_similarity']:.3f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Question Answering System (Similarity + RAG)\n",
    "class HybridQA:\n",
    "    def __init__(self, similarity_threshold=0.3, rag_top_k=3):\n",
    "        self.similarity_qa = SimilarityQA(threshold=similarity_threshold)\n",
    "        self.rag_system = SimpleRAG(top_k=rag_top_k)\n",
    "        \n",
    "    def train(self, documents, qa_pairs):\n",
    "        \"\"\"Train both systems\"\"\"\n",
    "        self.similarity_qa.train(documents, qa_pairs)\n",
    "        self.rag_system.add_documents(documents)\n",
    "        \n",
    "    def answer_question(self, question):\n",
    "        \"\"\"Hybrid approach: try similarity first, then RAG\"\"\"\n",
    "        # Try similarity-based approach first\n",
    "        similarity_result = self.similarity_qa.find_best_answer(question)\n",
    "        \n",
    "        # If similarity approach gives a good answer, use it\n",
    "        if similarity_result['source'] in ['QA_pairs', 'documents'] and similarity_result['confidence'] > 0.4:\n",
    "            return {\n",
    "                'question': question,\n",
    "                'answer': similarity_result['answer'],\n",
    "                'method': 'similarity_based',\n",
    "                'confidence': similarity_result['confidence'],\n",
    "                'source': similarity_result['source']\n",
    "            }\n",
    "        \n",
    "        # Otherwise, use RAG approach\n",
    "        rag_result = self.rag_system.answer_question(question)\n",
    "        \n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': rag_result['answer'],\n",
    "            'method': 'rag_based',\n",
    "            'confidence': rag_result['top_similarity'],\n",
    "            'source': 'retrieved_documents'\n",
    "        }\n",
    "\n",
    "# Initialize Hybrid QA system\n",
    "hybrid_qa = HybridQA(similarity_threshold=0.2, rag_top_k=3)\n",
    "hybrid_qa.train(documents, qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Hybrid QA System\n",
    "hybrid_test_questions = [\n",
    "    \"What is machine learning?\",  # Should use similarity (exact match)\n",
    "    \"Explain deep learning concepts\",  # Should use RAG\n",
    "    \"How does computer vision work?\",  # Should use RAG\n",
    "    \"What programming languages are used for AI?\",  # Should use similarity\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYBRID QUESTION ANSWERING SYSTEM RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, question in enumerate(hybrid_test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    result = hybrid_qa.answer_question(question)\n",
    "    print(f\"   Answer: {result['answer']}\")\n",
    "    print(f\"   Method: {result['method']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"   Source: {result['source']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Evaluation and Comparison\n",
    "def evaluate_qa_systems():\n",
    "    \"\"\"Compare all three QA approaches\"\"\"\n",
    "    evaluation_questions = [\n",
    "        \"What is machine learning?\",\n",
    "        \"Tell me about Python programming\",\n",
    "        \"How does deep learning work?\",\n",
    "        \"What is reinforcement learning?\",\n",
    "        \"Explain big data concepts\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for question in evaluation_questions:\n",
    "        # Test similarity-based\n",
    "        sim_result = qa_model.find_best_answer(question)\n",
    "        \n",
    "        # Test RAG\n",
    "        rag_result = rag_system.answer_question(question)\n",
    "        \n",
    "        # Test hybrid\n",
    "        hybrid_result = hybrid_qa.answer_question(question)\n",
    "        \n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'similarity_confidence': sim_result['confidence'],\n",
    "            'rag_confidence': rag_result['top_similarity'],\n",
    "            'hybrid_method': hybrid_result['method'],\n",
    "            'hybrid_confidence': hybrid_result['confidence']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_qa_systems()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PERFORMANCE COMPARISON OF QA SYSTEMS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Question':<35} {'Similarity':<12} {'RAG':<12} {'Hybrid Method':<15} {'Hybrid Conf':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for result in evaluation_results:\n",
    "    question_short = result['question'][:30] + \"...\" if len(result['question']) > 30 else result['question']\n",
    "    print(f\"{question_short:<35} {result['similarity_confidence']:<12.3f} {result['rag_confidence']:<12.3f} {result['hybrid_method']:<15} {result['hybrid_confidence']:<12.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Demo Function\n",
    "def interactive_qa_demo():\n",
    "    \"\"\"Interactive function to test QA systems\"\"\"\n",
    "    \n",
    "    def ask_question(question, system='hybrid'):\n",
    "        \"\"\"Ask a question to the specified QA system\"\"\"\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if system == 'similarity' or system == 'all':\n",
    "            print(\"SIMILARITY-BASED ANSWER:\")\n",
    "            sim_result = qa_model.find_best_answer(question)\n",
    "            print(f\"Answer: {sim_result['answer']}\")\n",
    "            print(f\"Confidence: {sim_result['confidence']:.3f} | Source: {sim_result['source']}\")\n",
    "            \n",
    "        if system == 'rag' or system == 'all':\n",
    "            print(\"\\nRAG-BASED ANSWER:\")\n",
    "            rag_result = rag_system.answer_question(question)\n",
    "            print(f\"Answer: {rag_result['answer']}\")\n",
    "            print(f\"Confidence: {rag_result['top_similarity']:.3f}\")\n",
    "            \n",
    "        if system == 'hybrid' or system == 'all':\n",
    "            print(\"\\nHYBRID ANSWER:\")\n",
    "            hybrid_result = hybrid_qa.answer_question(question)\n",
    "            print(f\"Answer: {hybrid_result['answer']}\")\n",
    "            print(f\"Method: {hybrid_result['method']} | Confidence: {hybrid_result['confidence']:.3f}\")\n",
    "    \n",
    "    return ask_question\n",
    "\n",
    "# Create demo function\n",
    "ask_question = interactive_qa_demo()\n",
    "\n",
    "# Demo examples\n",
    "print(\"INTERACTIVE QA DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test with different types of questions\n",
    "ask_question(\"What is artificial intelligence?\", \"all\")\n",
    "ask_question(\"How does machine learning differ from traditional programming?\", \"hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21729d32",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "### Three Question Answering Approaches Implemented:\n",
    "\n",
    "1. **Similarity-based QA Model**:\n",
    "   - Uses TF-IDF vectorization and cosine similarity\n",
    "   - Matches questions to pre-trained Q&A pairs and documents\n",
    "   - Implements conditional answering with confidence thresholds\n",
    "   - Best for: Exact or near-exact question matches\n",
    "\n",
    "2. **Simple RAG System**:\n",
    "   - Retrieval-Augmented Generation approach\n",
    "   - Retrieves top-k relevant documents for any query\n",
    "   - Generates answers by extracting relevant content\n",
    "   - Best for: Open-ended questions requiring document synthesis\n",
    "\n",
    "3. **Hybrid QA System**:\n",
    "   - Combines both similarity and RAG approaches\n",
    "   - Uses similarity-based method for high-confidence matches\n",
    "   - Falls back to RAG for complex or novel questions\n",
    "   - Best for: Production systems requiring robust coverage\n",
    "\n",
    "### Key Features:\n",
    "- ✅ **Conditional Answering**: Returns \"don't know\" for low-confidence queries\n",
    "- ✅ **Text Preprocessing**: Improves matching accuracy\n",
    "- ✅ **Confidence Scoring**: Provides reliability metrics\n",
    "- ✅ **Multiple Retrieval Methods**: Exact match + similarity search\n",
    "- ✅ **Performance Evaluation**: Compares different approaches\n",
    "\n",
    "### Real-world Applications:\n",
    "- Customer support chatbots\n",
    "- Educational Q&A systems\n",
    "- Documentation search engines\n",
    "- Knowledge base assistants"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
