{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk8Ynu5fGaHs"
   },
   "source": [
    "\n",
    "### Query Operations and Languages\n",
    "\n",
    "In this lab we will be doing:\n",
    "\n",
    "- Query expansion (with a thesaurus or WordNet and correlation matrix),  \n",
    "- Spelling correction (Edit distance, K-  Gram indexes, Context sensitive spelling correction),  \n",
    "- Query languages (Single-Word Queries, Context Queries, Boolean Queries, Structural Query, Natural Language)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2coA-8QQ-LJT",
    "outputId": "fd482426-330a-4c2d-d10a-fa947bfdd32d"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w32cG5eO--a-"
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Machine learning algorithms are transforming artificial intelligence applications.\",\n",
    "    \"Deep neural networks enable advanced pattern recognition capabilities.\",\n",
    "    \"Natural language processing helps computers understand human communication.\",\n",
    "    \"Computer vision systems can analyze and interpret visual data effectively.\",\n",
    "    \"Data mining techniques extract valuable insights from large datasets.\",\n",
    "    \"Software engineering principles guide robust system development practices.\"\n",
    "]\n",
    "\n",
    "query = \"machine learning\"\n",
    "vocab = [\"machine\", \"learning\", \"algorithms\", \"neural\", \"networks\", \"data\", \"analysis\", \"artificial\", \"intelligence\", \"computer\", \"vision\", \"software\", \"engineering\", \"natural\", \"language\", \"processing\"]\n",
    "corpus = \" \".join(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-TrGdKu-02v"
   },
   "source": [
    "## 1. Query Expansion (WordNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlS3_Tox-yR5",
    "outputId": "a8788976-75ea-4e7d-bae4-b8fe59098538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Query Expansion (WordNet):\n",
      "['get wind', 'discover', 'see', 'eruditeness', 'find out', 'take', 'learnedness', 'auto', 'automobile', 'car', 'machine', 'memorize', 'instruct', 'acquire', 'get a line', 'study', 'learning', 'check', 'ascertain', 'larn', 'get word', 'con', 'teach', 'acquisition', 'read', 'erudition', 'learn', 'simple machine', 'political machine', 'encyclopedism', 'encyclopaedism', 'motorcar', 'hear', 'memorise', 'watch', 'pick up', 'scholarship', 'determine']\n",
      "['get wind', 'discover', 'see', 'eruditeness', 'find out', 'take', 'learnedness', 'auto', 'automobile', 'car', 'machine', 'memorize', 'instruct', 'acquire', 'get a line', 'study', 'learning', 'check', 'ascertain', 'larn', 'get word', 'con', 'teach', 'acquisition', 'read', 'erudition', 'learn', 'simple machine', 'political machine', 'encyclopedism', 'encyclopaedism', 'motorcar', 'hear', 'memorise', 'watch', 'pick up', 'scholarship', 'determine']\n"
     ]
    }
   ],
   "source": [
    "def query_expansion_wordnet(query):\n",
    "    words = nltk.word_tokenize(query)\n",
    "    expanded_query = set(words)\n",
    "    for word in words:\n",
    "        for syn in wn.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded_query.add(lemma.name().replace('_', ' '))\n",
    "    return list(expanded_query)\n",
    "\n",
    "print(\"1. Query Expansion (WordNet):\")\n",
    "print(query_expansion_wordnet(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x94wJf6y_Ntv"
   },
   "source": [
    "## 2. Spelling Correction Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qa3rcqJe_I7H",
    "outputId": "f186f9d3-b981-44bd-ca1a-2dfe7d2d251f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2A. Edit Distance Correction:\n",
      "machine\n"
     ]
    }
   ],
   "source": [
    "# A. Edit Distance\n",
    "def edit_distance(w1, w2):\n",
    "    dp = [[0] * (len(w2)+1) for _ in range(len(w1)+1)]\n",
    "    for i in range(len(w1)+1):\n",
    "        for j in range(len(w2)+1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif w1[i-1] == w2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
    "    return dp[-1][-1]\n",
    "\n",
    "def correct_by_edit_distance(word, vocab):\n",
    "  min_dist = float('inf')\n",
    "  correction = word\n",
    "  for w in vocab:\n",
    "      dist = edit_distance(word, w)\n",
    "      if dist < min_dist:\n",
    "          min_dist = dist\n",
    "          correction = w\n",
    "  return correction\n",
    "\n",
    "\n",
    "print(\"\\n2A. Edit Distance Correction:\")\n",
    "print(correct_by_edit_distance(\"machne\", vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mk3IRgnx_kki",
    "outputId": "8d4a897a-07b1-4dc7-ec3c-aa46074d593f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2B. K-Gram Correction:\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "# B. K-Gram Index\n",
    "def generate_k_grams(word, k=3):\n",
    "    word = f\"${word}$\"\n",
    "    return [word[i:i+k] for i in range(len(word)-k+1)]\n",
    "\n",
    "def kgram_index(vocab, k=3):\n",
    "    index = defaultdict(set)\n",
    "    for word in vocab:\n",
    "        grams = generate_k_grams(word, k)\n",
    "        for g in grams:\n",
    "            index[g].add(word)\n",
    "    return index\n",
    "\n",
    "def correct_by_kgram(word, index, k=3):\n",
    "    grams = generate_k_grams(word, k)\n",
    "    candidates = Counter()\n",
    "    for g in grams:\n",
    "        for cand in index.get(g, []):\n",
    "            candidates[cand] += 1\n",
    "    return candidates.most_common(1)[0][0] if candidates else word\n",
    "\n",
    "\n",
    "print(\"\\n2B. K-Gram Correction:\")\n",
    "k_index = kgram_index(vocab)\n",
    "print(correct_by_kgram(\"lerning\", k_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9KT7G-w_khi",
    "outputId": "c1a7813c-dc39-43f5-fbf2-24b01d3cb961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2C. Context Sensitive:\n",
      "['machine', 'lerning', 'algorithms']\n"
     ]
    }
   ],
   "source": [
    "# C. Context Sensitive Correction (Bigram Based)\n",
    "def train_bigram_model(corpus):\n",
    "    tokens = nltk.word_tokenize(corpus.lower())\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    model = Counter(bigrams)\n",
    "    return model\n",
    "\n",
    "def correct_contextually(word_list, model):\n",
    "    corrected = [word_list[0]]\n",
    "    for i in range(1, len(word_list)):\n",
    "        prev_word = corrected[-1]\n",
    "        word = word_list[i]\n",
    "        candidates = [word] + [correct_by_edit_distance(word, model.keys())]\n",
    "        best_word = max(candidates, key=lambda w: model.get((prev_word, w), 0))\n",
    "        corrected.append(best_word)\n",
    "    return corrected\n",
    "\n",
    "print(\"\\n2C. Context Sensitive:\")\n",
    "bigram_model = train_bigram_model(corpus)\n",
    "print(correct_contextually([\"machine\", \"lerning\", \"algorithms\"], bigram_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx_kDAB__lSF"
   },
   "source": [
    "## 3. Query Language Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqXyPbUy_wlS",
    "outputId": "c81f11da-78d0-412f-cda3-23f56dc1709b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3A. Single-word Query:\n",
      "['Deep neural networks enable advanced pattern recognition capabilities.']\n"
     ]
    }
   ],
   "source": [
    "def single_word_query(word, documents):\n",
    "    return [doc for doc in documents if word in doc.lower()]\n",
    "\n",
    "\n",
    "print(\"\\n3A. Single-word Query:\")\n",
    "print(single_word_query(\"neural\", documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UbE7FP6Am_c",
    "outputId": "e9e8acf0-22e1-4ae4-a171-68d919e92eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3B. Boolean Query:\n",
      "['Machine learning algorithms are transforming artificial intelligence applications.']\n"
     ]
    }
   ],
   "source": [
    "def boolean_query(q, documents):\n",
    "    terms = q.lower().split()\n",
    "    result = set(documents)\n",
    "    if \"and\" in terms:\n",
    "        terms = [t for t in terms if t != \"and\"]\n",
    "        result = [doc for doc in documents if all(t in doc.lower() for t in terms)]\n",
    "    elif \"or\" in terms:\n",
    "        terms = [t for t in terms if t != \"or\"]\n",
    "        result = [doc for doc in documents if any(t in doc.lower() for t in terms)]\n",
    "    elif \"not\" in terms:\n",
    "        idx = terms.index(\"not\")\n",
    "        term = terms[idx+1]\n",
    "        result = [doc for doc in documents if term not in doc.lower()]\n",
    "    return result\n",
    "\n",
    "print(\"\\n3B. Boolean Query:\")\n",
    "print(boolean_query(\"machine AND learning\", documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xt6HSi03AoQY",
    "outputId": "cfe69d15-9d71-404e-8e5e-f7a3961f61ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3C. Natural Language Query:\n",
      "['Machine learning algorithms are transforming artificial intelligence applications.', 'Deep neural networks enable advanced pattern recognition capabilities.']\n"
     ]
    }
   ],
   "source": [
    "def natural_language_query(nl_query, documents):\n",
    "    tokens = nltk.word_tokenize(nl_query.lower())\n",
    "    return [doc for doc in documents if any(t in doc.lower() for t in tokens)]\n",
    "\n",
    "print(\"\\n3C. Natural Language Query:\")\n",
    "print(natural_language_query(\"How does artificial intelligence work?\", documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7yjo8_6Apsy",
    "outputId": "d65ee420-7109-455d-fa34-1209ffdc4a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3D. Structural Query:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def structural_query(structure_query, documents):\n",
    "    # Dummy: match title:xxx or body:xxx\n",
    "    m = re.match(r\"(title|body):(\\w+)\", structure_query.lower())\n",
    "    if m:\n",
    "        field, word = m.groups()\n",
    "        return [doc for doc in documents if word in doc.lower()]\n",
    "    return []\n",
    "\n",
    "\n",
    "print(\"\\n3D. Structural Query:\")\n",
    "print(structural_query(\"title:neural\", documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj_uY62JBXV_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
